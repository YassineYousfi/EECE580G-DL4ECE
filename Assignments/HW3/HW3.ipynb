{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EDB9X9DrCT4F"},"source":["# EECE 580G Assignment 3"]},{"cell_type":"markdown","metadata":{"id":"tYjuoxNKgwL-"},"source":["## Problem 2 - Linear regression - Intro to Fairness in ML\n","The goal of this short problem is to use linear regression in a \"real world\" dataset, the boston house-prices dataset. We will also use it to introduce \"fairness\" problems in Machine Learning.\n","1. Load the dataset, split it into a train/test set, and use the Pipeline class to Standardize features (removing the mean and scaling to unit variance) and perform Linear Regression.\n","2. Train the pipeline and visualize the predictions vs ground truth values on the test set.\n","\n","Read a little more about the boston house prices dataset below.\n","Features: B and LSTAT are sensitive features! In general having data about race, skin color, religion, sexual orientation, socioeconomic status, income, health, etc. is a recipe for building a biased ML system. Such features should be avoided.\n","\n","A measure of (un-)fairness of a Machine Learning algorithm with respect to two subsets $Z_1$ and $Z_0$ is $ \\left\\lvert \\frac{1}{|Z_1|} \\sum_{i \\in Z_1} \\hat{y}_{i} - \\frac{1}{|Z_0|} \\sum_{i \\in Z_0} \\hat{y}_{i} \\right\\rvert $, i.e. the difference between the mean prediction in $Z_1$ and the mean prediction in $Z_0$. \n","\n","3. Consider $Z_1$ to be the samples in the test set where LSTAT is higher than the median and $Z_0$ lower than the median. Compute the fairness proxy.\n","\n","4. Drop the feature B and LSTAT and retrain the pipeline and compute the \n","fairness proxy, is it better? \n","\n","The fairness proxy is still pretty bad, this is because other features are directly correlated to the sensitive features. \n","\n","Consider $x_1$ and $x_2$ to be the sensitive features, a way of \"orthogonalizing\" the rest of the dataset is the perform the following transformation (Gram Schmidt process):\n","$$\\begin{split}\\begin{split}\n","v_1 & = x_1 \\\\\n","v_2 & = x_2 - \\frac{x_2.v_1}{v_1.v_1}v_1\\\\\n","v_3 & = x_3 - \\frac{x_3.v_1}{v_1.v_1}v_1 - \\frac{x_3.v_2}{v_2.v_2}v_2\\\\\n","... \\\\\n","v_n & = x_n - \\frac{x_n.v_1}{v_1.v_1}v_1 - \\frac{x_n.v_2}{v_2.v_2}v_2\n","\\end{split}\\end{split}$$\n","\n","The dataset $V=[v_3,...,v_n]$ is then used to train the model\n","\n","5. Use the implementation provided to improve the fairness of the model. Comment on your results."]},{"cell_type":"code","metadata":{"id":"5DA3BSsjZf6e"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_boston\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3t0mFwo5Tlf","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1601769394316,"user_tz":240,"elapsed":399,"user":{"displayName":"Yassine Yousfi","photoUrl":"","userId":"06317191099946336363"}},"outputId":"86f0c4cf-7669-46f4-b457-f36f77d3fa9d"},"source":["X, y = load_boston(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 13)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"wl2uvBdCg7pp"},"source":["X, y = load_boston(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)\n","# 1. YOUR CODE HERE\n","# pipe = Pipeline([\n","#     (\"scale\", # YOUR CODE HERE),\n","#     (\"model\", # YOUR CODE HERE)\n","# ])\n","\n","# 2. \n","# YOUR CODE HERE - fit the pipe \n","# YOUR CODE HERE y_hat = # predict using the pipe \n","\n","plt.scatter(y_hat, y_test, s=12)\n","plt.plot(y_hat, y_hat, c='gray', alpha=0.6, linewidth=1)\n","plt.xlabel(\"Predictions\")\n","plt.ylabel(\"Ground truth\")\n","plt.title('MSE = '+str(mean_squared_error(y_hat,y_test)))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32pIiZVfg_jQ"},"source":["print(load_boston()['DESCR'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5gRJj2OGhLJx"},"source":["# 3. YOUR CODE HERE\n","def fairness_proxy(sensitive_feature, y_hat):\n","  '''\n","  sensitive_feature = X_test[:,-1] for LSTAT\n","  Z_1 are the samples in the test set where idx is higher than the median and Z_0  lower than the median\n","  '''\n","  mask = sensitive_feature > np.quantile(sensitive_feature, 0.5)\n","  return 0 # YOUR CODE HERE\n","\n","sensitive_feature = X_test[:,-1]\n","print('Fairness proxy = ', fairness_proxy(sensitive_feature, y_hat))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4V63FEUmvFL"},"source":["# 4. YOUR CODE HERE\n","# Drop B and LSTAT\n","# fit pipeline \n","# Predict on test set\n","# Show scatter plot\n","# Show Fairness proxy \n","# Comment"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qtEprG2lQVR"},"source":["normalized_dot = lambda a,b: a.dot(b)/(b.dot(b))\n","\n","V = np.zeros_like(X)\n","V[:,-1] = X[:,-1]\n","V[:,-2] = X[:,-2] - normalized_dot(X[:,-2], V[:,-1])*V[:,-1]\n","for j in range(2,X.shape[1]):\n","  V[:,-j-1] = X[:,-j-1] - normalized_dot(X[:,-j-1], V[:,-1])*V[:,-1] - normalized_dot(X[:,-j-1], V[:,-2])*V[:,-2]\n","\n","X_train_ortho, X_test_ortho, y_train, y_test = train_test_split(V[:,:-2], y, random_state=2020)\n","\n","# 5. YOUR CODE HERE\n","# fit pipeline on X_train_ortho\n","# predict on X_test_ortho\n","# Show scatter plot\n","# Show Fairness proxy \n","# Comment"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ngWt6UNZvpoB"},"source":["## Problem 3 - SGD"]},{"cell_type":"markdown","metadata":{"id":"qmwV2042vtaC"},"source":["$$ f(\\textbf{x}) = \\frac{1}{2}[(\\eta_1 + x_1)^2 + (\\eta_2 +x_2)^2] $$ where $ \\eta_1,\\eta_2 \\sim \\mathcal{N}(0,1)$\n","\n","\n","1.   What is $E[f(\\textbf{x})]$?\n","3.   Write down the gradient of $f$\n","4.   Complete the code below find the minimum of $f$ using SGD with $\\tau = 0.1$ and a 100 iterations\n","5.   Tune the learning rate $\\tau(t)$ as directed by the code, comment."]},{"cell_type":"code","metadata":{"id":"jeStmwk0vzqp"},"source":["import numpy as np\n","from tqdm import tqdm_notebook as tqdm\n","import matplotlib.pyplot as plt \n","\n","f = lambda x, eta : ( (eta[0]+x[0])**2 + (eta[1]+x[1])**2 ) / 2 \n","E_f = lambda x: # YOUR CODE HERE\n","Grad_f = lambda x, eta : # YOUR CODE HERE\n","\n","def StochasticGradDescentArray(Grad_f, x0, nbiter, tau, seed=0):\n","    x = x0\n","    xlist = [list(x0)]\n","    np.random.seed(seed)\n","    for t in range(1,nbiter+1):  \n","        eta = np.random.normal(size=(2)) # 1 sample of eta_1, eta_2\n","        x = # YOUR CODE HERE (tau is a function of t) do the gradient update  \n","        xlist = xlist + [list(x)]\n","    return np.array(xlist)\n","\n","x = np.linspace(-1.5,1.5,250)\n","y = np.linspace(-1.5,1.5,250)\n","\n","[u,v] = np.meshgrid(x,y)\n","F = E_f([u,v])\n","\n","xarray = StochasticGradDescentArray(Grad_f,[1,1], 100, tau = lambda t: 0.1)\n","plt.figure(figsize=(8,8))\n","plt.scatter(0,0, label='Optima')\n","plt.contourf(x, y, F, 35)\n","plt.plot(xarray[:,0], xarray[:,1], 'w.-')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QcqZa7MwHYY"},"source":["powers = np.linspace(0.5,1.2,30)\n","errors = []\n","for p in tqdm(powers):\n","  errors_seed = []\n","  for s in range(100):\n","    xarray = StochasticGradDescentArray(Grad_f, [1,1], 100, tau = lambda t: 1/(t**p), seed=s)\n","    errors_seed.append(np.linalg.norm(xarray[-1]-[0,0]))\n","  errors.append(np.mean(errors_seed))\n","\n","plt.plot(powers, errors, c='b')\n","plt.xlabel('Learning rate decay parameter')\n","plt.ylabel('Distance to optimum')\n","plt.show()\n","\n","# Comment"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YqWu9_GppF_3"},"source":["## Problem 4 - MLP using tf.keras.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"D5OX8vDnpP-0"},"source":["\n","### I. MNIST dataset\n","\n","1.   The MNIST dataset is available in tf.keras.datasets, we load it using `load_data()`\n","*   Use the Sequential API to code this network:\n","\n","> 1 hidden layer, size = 128, acitvation = ReLU, dropout regularization rate = 0.2.\n","> \n","> The network outputs a probability distribution over the 10 classes (digits), this means that you need to add a softmax layer at the end of the model\n","\n","*   Show `model.summary()`\n","*   Read the documentation of the following loss functions: `CategoricalCrossentropy`, `BinaryCrossentropy`, `SparseCategoricalCrossentropy`, and `MeanSquaredError`, which one do you choose. (Hint: look at how `y_train` is provided, you can choose 2 of these but one requires more code)    \n","*   Train it using the adam optimizer for 5 epochs and an appropriate loss function, you can use default learning rate, batch size, etc.\n","*   Evaluate it on the test set\n","2.   Load `x_mystery.npy`, don't look at it! Use your model to predict the digit in the image Hint: you can use the model as `model(x_mystery)` and show a bar plot of the outputs of the network\n","*   Now plot `x_mystery` using `imshow`, comment?\n","3. What does the `shuffle` function do?\n","*   Reshape and show a few samples \n","*   Train the same model on the shuffled data\n","*   Comment \n","\n","### II. Fashion MNIST dataset\n","\n","1.  Do the same thing (copy your code in another cell, only I.1) for the fashion_mnist dataset. Use the script provided to look at images from each class before starting the training.\n","2.  Save your trained model (on fashion_mnist) using the `SavedModel` format, (read the documentation of `model.save`) this will create a directory that you can reuse later. `zip` the folder and add it to your submission.\n"]},{"cell_type":"code","metadata":{"id":"y2I8cPWDpNyS","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1602174439383,"user_tz":240,"elapsed":4164,"user":{"displayName":"Yassine Yousfi","photoUrl":"","userId":"06317191099946336363"}},"outputId":"0068efcd-04e5-48ea-aaa2-06b9ef35cf3a"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# I.\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1) # Flattening \n","x_train, x_test = x_train / 255.0, x_test / 255.0 # Normalizing \n","\n","# 1. YOUR CODE HERE\n","def get_model():\n","  model = tf.keras.models.Sequential()\n","  # YOUR CODE HERE\n","  #\n","  # \n","  return model\n","# model = get_model()\n","# model.summary()\n","# model.compile( # YOUR CODE )\n","# model.fit( # YOUR CODE )\n","# model.evaluate( # YOUR CODE )\n","\n","# 2. YOUR CODE HERE\n","# Mystery\n","# Bar plot\n","# Comment\n","# Show mystery (don't forget to reshape to 28x28 when plotting)\n","\n","def shuffle(x_train, x_test, seed=0):\n","  np.random.seed(seed)\n","  perm = np.random.permutation(x_train.shape[1])\n","  return x_train[:,perm], x_test[:,perm]\n","\n","x_train, x_test = shuffle(x_train, x_test)\n","\n","# 3. YOUR CODE HERE\n","# Show some samples of x_train after shuffling (don't forget to reshape to 28x28 when plotting)\n","# model = get_model()\n","# model.compile( # YOUR CODE HERE )\n","# model.fit( # YOUR CODE HERE )\n","# model.evaluate( # YOUR CODE HERE )\n","# Comment"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J9-zQV42pr8r"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(x_train[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[y_train[i]])\n","plt.show()\n","\n","x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1) # Flattening "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgdsizvcqj_X"},"source":["# II. YOUR CODE HERE\n","# model = get_model()\n","# model.compile( # YOUR CODE HERE )\n","# model.fit( # YOUR CODE HERE )\n","# model.evaluate( # YOUR CODE HERE )\n","# model.save( #YOUR CODE HERE )"],"execution_count":null,"outputs":[]}]}