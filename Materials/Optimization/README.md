# Introduction to Numerical Optimization

Basic numerical optimization for Deep Learning
- First order methods: Gradient Descent - Momentum
- Second order methods: Newton method
- Approximate second order methods: Adam
- Practical details for deep learning